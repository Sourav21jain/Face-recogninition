{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load HAAR face classifier\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Load functions\n",
    "def face_extractor(img):\n",
    "    # Function detects faces and returns the cropped face\n",
    "    # If no face detected, it returns the input image\n",
    "    \n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    if faces is ():\n",
    "        return None\n",
    "    \n",
    "    # Crop all faces found\n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "\n",
    "    return cropped_face\n",
    "\n",
    "# Initialize Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "\n",
    "# Collect 100 samples of your face from webcam input\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if face_extractor(frame) is not None:\n",
    "        count += 1\n",
    "        face = cv2.resize(face_extractor(frame), (200, 200))\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Save file in specified directory with unique name\n",
    "        file_name_path = '/root/Desktop/faceRecog/vimal/harsh' + str(count) + '.jpg'\n",
    "        cv2.imwrite(file_name_path, face)\n",
    "\n",
    "        # Put count on images and display live count\n",
    "        cv2.putText(face, str(count), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "        cv2.imshow('Face Cropper', face)\n",
    "        \n",
    "    else:\n",
    "        print(\"Face not found\")\n",
    "        pass\n",
    "\n",
    "    if cv2.waitKey(1) == 13 or count == 100: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.6.0\n",
      "Model trained sucessefully\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "print(cv2.__version__)\n",
    "# Get the training data we previously made\n",
    "data_path = '/root/Desktop/faceRecog/vimal/'\n",
    "# a=listdir('d:/faces')\n",
    "# print(a)\n",
    "# \"\"\"\n",
    "onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path, f))]\n",
    "\n",
    "# Create arrays for training data and labels\n",
    "Training_Data, Labels = [], []\n",
    "\n",
    "# Open training images in our datapath\n",
    "# Create a numpy array for training data\n",
    "for i, files in enumerate(onlyfiles):\n",
    "    image_path = data_path + onlyfiles[i]\n",
    "    images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    Training_Data.append(np.asarray(images, dtype=np.uint8))\n",
    "    Labels.append(i)\n",
    "# Create a numpy array for both training data and labels\n",
    "Labels = np.asarray(Labels, dtype=np.int32)\n",
    "vimal_model=cv2.face_LBPHFaceRecognizer.create()\n",
    "#Initialize facial recognizer\n",
    "#model = cv2.face_LBPHFaceRecognizer.create()\n",
    "#model=cv2.f\n",
    "# NOTE: For OpenCV 3.0 use cv2.face.createLBPHFaceRecognizer()\n",
    "\n",
    "# Let's train our model \n",
    "vimal_model.train(np.asarray(Training_Data), np.asarray(Labels))\n",
    "print(\"Model trained sucessefully\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 35.26893080721191)\n",
      "(11, 35.70029997920774)\n",
      "(4, 37.41374904938985)\n",
      "(13, 37.32139147856702)\n",
      "(11, 37.05086956647075)\n",
      "(20, 45.51931846861912)\n",
      "(12, 39.596923704731374)\n",
      "(3, 42.01503826611005)\n",
      "(12, 43.91019561143479)\n",
      "(12, 37.00195124724908)\n",
      "(3, 39.32360478111064)\n",
      "(4, 37.15227469436102)\n",
      "(1, 36.062586661795905)\n",
      "(3, 38.92921405362858)\n",
      "(12, 37.64797056577328)\n",
      "(1, 40.37375978171672)\n",
      "(15, 66.00728072481235)\n",
      "(1, 40.51186299655803)\n",
      "(1, 40.503312490125424)\n",
      "(5, 41.9973336698152)\n",
      "(0, 40.66762741818299)\n",
      "(4, 42.10670522792631)\n",
      "(4, 43.86367813494105)\n",
      "(5, 38.767414949082095)\n",
      "(5, 39.233549092843845)\n",
      "(5, 41.7010008618148)\n",
      "(5, 41.82538979436528)\n",
      "(5, 40.71983998270122)\n",
      "(20, 64.46325170131675)\n",
      "(12, 45.3229261399185)\n",
      "(20, 40.91454993420526)\n",
      "(12, 38.4162459753169)\n",
      "(16, 41.048504095039256)\n",
      "(16, 39.886645195871765)\n",
      "(14, 41.84972298655041)\n",
      "(14, 40.28257112461251)\n",
      "(16, 47.56724499953243)\n",
      "(16, 45.25642250674308)\n",
      "(16, 42.56814497495979)\n",
      "(18, 38.00085760437249)\n",
      "(14, 39.396695358748374)\n",
      "(12, 40.59508051961368)\n",
      "(14, 39.016258735227446)\n",
      "(12, 37.935406245459525)\n",
      "(15, 38.66234175366209)\n",
      "(16, 39.66686316800013)\n",
      "(19, 40.43913043049049)\n",
      "(16, 40.93727287222601)\n",
      "(12, 40.67601117170076)\n",
      "(12, 37.06096758091476)\n",
      "(18, 38.79896644291928)\n",
      "(16, 38.92234813454595)\n",
      "(12, 38.134231071216824)\n",
      "(0, 45.113887561389106)\n",
      "(12, 34.59992700583362)\n",
      "(12, 36.628396624729206)\n",
      "(16, 37.3848701084084)\n",
      "(20, 38.31753097209443)\n",
      "(20, 38.142497554172145)\n",
      "(20, 37.278973817120374)\n",
      "(19, 37.04805161106297)\n",
      "(16, 35.728579974600294)\n",
      "(16, 39.68300131636786)\n",
      "(19, 41.00439381218022)\n",
      "(19, 41.07930113790731)\n",
      "(18, 41.26598405436795)\n",
      "(16, 39.780695746725534)\n",
      "(12, 37.94009666040453)\n",
      "(14, 38.796501421644074)\n",
      "(16, 37.9622548242979)\n",
      "(17, 40.17118268650822)\n",
      "(16, 38.47646039513027)\n",
      "(16, 38.214412171144026)\n",
      "(16, 40.96891325082412)\n",
      "(16, 42.09864328110042)\n",
      "(16, 44.37661785872966)\n",
      "(16, 43.79306804131182)\n",
      "(16, 37.967543116992566)\n",
      "(16, 36.963375166333684)\n",
      "(14, 38.74782611810404)\n",
      "(16, 36.00987828663363)\n",
      "(16, 37.23431732097382)\n",
      "(13, 35.35012420592614)\n",
      "(16, 35.378864359609935)\n",
      "(16, 37.597965516655904)\n",
      "(16, 37.768019450904205)\n",
      "(16, 36.86302531474342)\n",
      "(16, 39.11934955648456)\n",
      "(12, 34.52269717667747)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import webbrowser\n",
    "import os\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "def face_detector(img, size=0.5):\n",
    "    \n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return img, []\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(roi, (200, 200))\n",
    "    return img, roi\n",
    "\n",
    "\n",
    "# Open Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    image, face = face_detector(frame)\n",
    "    \n",
    "    try:\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Pass face to prediction model\n",
    "        # \"results\" comprises of a tuple containing the label and the confidence value\n",
    "        results = vimal_model.predict(face)\n",
    "        print(results)\n",
    "        if results[1] < 500:\n",
    "            confidence = int( 100 * (1 - (results[1])/400) )\n",
    "            display_string = str(confidence) + '% Confident it is User'\n",
    "            \n",
    "        cv2.putText(image, display_string, (100, 120), cv2.FONT_HERSHEY_COMPLEX, 1, (255,120,150), 2)\n",
    "        \n",
    "        if confidence > 70:\n",
    "            cv2.putText(image, \"harsh\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "            os.system(\"usermod -s /bin/bash hnama\")\n",
    "            \n",
    "                       \n",
    "        else:\n",
    "            cv2.putText(image,\"Locked\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "\n",
    "    except:\n",
    "        cv2.putText(image, \"No Face Found\", (220, 120) , cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.putText(image, \"Locked\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.imshow('Face Recognition', image )\n",
    "        pass\n",
    "        \n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
